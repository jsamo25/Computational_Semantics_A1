#using 10fold CV for Bow
 Basic data statistics
              rating  n_characters      n_tokens   n_sentences  n_positive_lex  \
count  20000.000000  20000.000000  20000.000000  20000.000000    20000.000000
mean       5.477750   1325.268450    282.753200     10.840100        1.420000
std        3.466498   1008.338121    211.909904      8.302673        1.681054
min        1.000000     52.000000     11.000000      1.000000        0.000000
25%        2.000000    701.000000    151.000000      6.000000        0.000000
50%        5.500000    978.000000    210.000000      9.000000        1.000000
75%        9.000000   1609.000000    343.250000     13.000000        2.000000
max       10.000000  13704.000000   2818.000000    282.000000       30.000000

       n_negative_lex
count    20000.000000
mean         0.864300
std          1.282446
min          0.000000
25%          0.000000
50%          0.000000
75%          1.000000
max         25.000000

 Average number of words 282.7532

 Average number of sentences 10.8401

Sentences average
 sentiment
False    11.1112
True     10.5690
Name: n_sentences, dtype: float64

Words average
 sentiment
False    280.8858
True     284.6206
Name: n_tokens, dtype: float64

 ***************************************
    Using hand-chosen features as input
 ***************************************
Selected features:
 [n_characters]
 [n_tokens]
 [n_sentences]
 [n_positive_lex]
 [n_negative_lex]

 Initial model score
training set: 0.6633571428571429
testing set: 0.6736666666666666

 Initial model Coefficients [ 0.   -0.01 -0.02  0.4  -0.63]

Final model score [hand-chosen features] and 10-f [CrossValidation]
training set: 0.6643571428571429
testing set: 0.6753333333333333

Final model Coefficients [ 0.   -0.01 -0.02  0.39 -0.61]

 Compare to baselines:
accuracy of all-positive baseline 0.5
accuracy of all-negative baseline 0.5
accuracy of all-random baseline 0.4972

Confusion matrix
normalization= False
[[1906 1090]
 [ 858 2146]]

 Printing evaluation metrics for hand-chosen features

 True Negatives:  1906
 True Positives:  2146
 False Positives:  1090
 False Negatives:  858

 Accuracy:  68.0
 Precision:  66.0
 Recall:  71.0
 F1 Score:  69.0

 *********************************
    Using BOW as feature input
 *********************************

 Initial model score, using a weak regularization, C=10
training set: 1.0
testing set: 0.8746666666666667

adjusting regularization...

Score with stronger regularization, C=0.01
training set: 0.9217857142857143
testing set: 0.8773333333333333

Changing LR model to use CrossValidation [BOW features]

Final model score [BOW features] and [CrossValidation]
training set: 0.9637857142857142
testing set: 0.8865

Confusion matrix
normalization= False
[[2620  376]
 [ 305 2699]]

 Printing evaluation metrics for BOW features

 True Negatives:  2620
 True Positives:  2699
 False Positives:  376
 False Negatives:  305

 Accuracy:  89.0
 Precision:  88.0
 Recall:  90.0
 F1 Score:  89.0

Process finished with exit code 0



#with external lexicon files , 5f in bow
"C:\Python Projects\Computational_Semantics_A1\venv\Scripts\python.exe" "C:/Python Projects/Computational_Semantics_A1/main_graded.py"

 Basic data statistics
              rating  n_characters      n_tokens   n_sentences  n_positive_lex  \
count  20000.000000  20000.000000  20000.000000  20000.000000    20000.000000
mean       5.477750   1325.268450    282.753200     10.840100        9.292600
std        3.466498   1008.338121    211.909904      8.302673        7.418924
min        1.000000     52.000000     11.000000      1.000000        0.000000
25%        2.000000    701.000000    151.000000      6.000000        4.000000
50%        5.500000    978.000000    210.000000      9.000000        7.000000
75%        9.000000   1609.000000    343.250000     13.000000       12.000000
max       10.000000  13704.000000   2818.000000    282.000000       89.000000

       n_negative_lex
count    20000.000000
mean         8.614150
std          7.780231
min          0.000000
25%          3.000000
50%          7.000000
75%         11.000000
max         86.000000

 Average number of words 282.7532

 Average number of sentences 10.8401

Sentences average
 sentiment
False    11.1112
True     10.5690
Name: n_sentences, dtype: float64

Words average
 sentiment
False    280.8858
True     284.6206
Name: n_tokens, dtype: float64

 ***************************************
    Using hand-chosen features as input
 ***************************************
Selected features:
 [n_characters]
 [n_tokens]
 [n_sentences]
 [n_positive_lex]
 [n_negative_lex]

 Initial model score
training set: 0.7325
testing set: 0.7328333333333333

 Initial model Coefficients [ 0.   -0.01 -0.03  0.19 -0.21]

Final model score [hand-chosen features] and 10-f [CrossValidation]
training set: 0.7329285714285714
testing set: 0.732

Final model Coefficients [ 0.   -0.01 -0.03  0.19 -0.21]

 Compare to baselines:
accuracy of all-positive baseline 0.5
accuracy of all-negative baseline 0.5
accuracy of all-random baseline 0.49945

Confusion matrix
normalization= False
[[2190  825]
 [ 783 2202]]

 Printing evaluation metrics for hand-chosen features

 True Negatives:  2190
 True Positives:  2202
 False Positives:  825
 False Negatives:  783

 Accuracy:  73.0
 Precision:  73.0
 Recall:  74.0
 F1 Score:  73.0

 *********************************
    Using BOW as feature input
 *********************************

 Initial model score, using a weak regularization, C=10
training set: 1.0
testing set: 0.8645

adjusting regularization...

Score with stronger regularization, C=0.01
training set: 0.926
testing set: 0.8696666666666667

Changing LR model to use CrossValidation [BOW features]

Final model score [BOW features] and [CrossValidation]
training set: 0.9662857142857143
testing set: 0.877

Confusion matrix
normalization= False
[[2597  418]
 [ 320 2665]]

 Printing evaluation metrics for BOW features

 True Negatives:  2597
 True Positives:  2665
 False Positives:  418
 False Negatives:  320

 Accuracy:  88.0
 Precision:  86.0
 Recall:  89.0
 F1 Score:  88.0

Process finished with exit code 0


#Using simple hand-made lexicon list
 Basic data statistics
              rating  n_characters      n_tokens   n_sentences  n_positive_lex  \
count  20000.000000  20000.000000  20000.000000  20000.000000    20000.000000
mean       5.477750   1325.268450    282.753200     10.840100        1.420000
std        3.466498   1008.338121    211.909904      8.302673        1.681054
min        1.000000     52.000000     11.000000      1.000000        0.000000
25%        2.000000    701.000000    151.000000      6.000000        0.000000
50%        5.500000    978.000000    210.000000      9.000000        1.000000
75%        9.000000   1609.000000    343.250000     13.000000        2.000000
max       10.000000  13704.000000   2818.000000    282.000000       30.000000

       n_negative_lex
count    20000.000000
mean         0.864300
std          1.282446
min          0.000000
25%          0.000000
50%          0.000000
75%          1.000000
max         25.000000

 Average number of words 282.7532

 Average number of sentences 10.8401

Sentences average
 sentiment
False    11.1112
True     10.5690
Name: n_sentences, dtype: float64

Words average
 sentiment
False    280.8858
True     284.6206
Name: n_tokens, dtype: float64

 ***************************************
    Using hand-chosen features as input
 ***************************************
Selected features:
 [n_characters]
 [n_tokens]
 [n_sentences]
 [n_positive_lex]
 [n_negative_lex]

 Initial model score
training set: 0.6665714285714286
testing set: 0.6681666666666667

 Initial model Coefficients [ 0.   -0.01 -0.02  0.39 -0.64]

Final model score [hand-chosen features] and 10-f [CrossValidation]
training set: 0.6685714285714286
testing set: 0.6678333333333333

Final model Coefficients [ 0.   -0.01 -0.02  0.38 -0.63]

 Compare to baselines:
accuracy of all-positive baseline 0.5
accuracy of all-negative baseline 0.5
accuracy of all-random baseline 0.50285

Confusion matrix
normalization= False
[[1939 1125]
 [ 868 2068]]

 Printing evaluation metrics for hand-chosen features

 True Negatives:  1939
 True Positives:  2068
 False Positives:  1125
 False Negatives:  868

 Accuracy:  67.0
 Precision:  65.0
 Recall:  70.0
 F1 Score:  67.0

 *********************************
    Using BOW as feature input
 *********************************

 Initial model score, using a weak regularization, C=10
training set: 1.0
testing set: 0.872

adjusting regularization...

Score with stronger regularization, C=0.01
training set: 0.923
testing set: 0.8786666666666667

Changing LR model to use CrossValidation [BOW features]

Final model score [BOW features] and [CrossValidation]
training set: 0.9645714285714285
testing set: 0.8846666666666667

Confusion matrix
normalization= False
[[2691  373]
 [ 319 2617]]

 Printing evaluation metrics for BOW features

 True Negatives:  2691
 True Positives:  2617
 False Positives:  373
 False Negatives:  319

 Accuracy:  88.0
 Precision:  88.0
 Recall:  89.0
 F1 Score:  88.0

Process finished with exit code 0